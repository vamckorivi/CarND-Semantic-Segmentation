{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"CgftHGVRwrLA","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":103},"outputId":"c30745f2-711f-4c70-eed0-cfbcab8e365f","executionInfo":{"status":"ok","timestamp":1532199628990,"user_tz":420,"elapsed":10057,"user":{"displayName":"vamshi korivi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"112593885874769367656"}}},"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()"],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-987f39f9-d220-40c9-ba43-3836817f710c\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-987f39f9-d220-40c9-ba43-3836817f710c\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving helper.py to helper.py\n","Saving project_tests.py to project_tests.py\n"],"name":"stdout"}]},{"metadata":{"id":"FWucVjUO0YVP","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":122},"outputId":"9db33902-d4bb-4142-8754-154e5267f084","executionInfo":{"status":"ok","timestamp":1532199635483,"user_tz":420,"elapsed":2778,"user":{"displayName":"vamshi korivi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"112593885874769367656"}}},"cell_type":"code","source":["!pip install tqdm"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting tqdm\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/24/6ab1df969db228aed36a648a8959d1027099ce45fad67532b9673d533318/tqdm-4.23.4-py2.py3-none-any.whl (42kB)\n","\u001b[K    100% |████████████████████████████████| 51kB 2.5MB/s \n","\u001b[?25hInstalling collected packages: tqdm\n","Successfully installed tqdm-4.23.4\n"],"name":"stdout"}]},{"metadata":{"id":"5YWiAV811wNb","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":51},"outputId":"f8fd8280-fc8c-4a98-aff5-10dcceb75b66","executionInfo":{"status":"ok","timestamp":1532199638238,"user_tz":420,"elapsed":1169,"user":{"displayName":"vamshi korivi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"112593885874769367656"}}},"cell_type":"code","source":["import os.path\n","import tensorflow as tf\n","import helper\n","import warnings\n","from distutils.version import LooseVersion\n","import project_tests as tests\n","\n","# Check TensorFlow Version\n","assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\n","print('TensorFlow Version: {}'.format(tf.__version__))\n","\n","# Check for a GPU\n","if not tf.test.gpu_device_name():\n","    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n","else:\n","    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["TensorFlow Version: 1.9.0\n","Default GPU Device: /device:GPU:0\n"],"name":"stdout"}]},{"metadata":{"id":"07ZSpu7L2DV2","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"1912651e-af3f-4a14-e57c-89912d4c681f","executionInfo":{"status":"ok","timestamp":1532199642087,"user_tz":420,"elapsed":330,"user":{"displayName":"vamshi korivi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"112593885874769367656"}}},"cell_type":"code","source":["#https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf\n","def load_vgg(sess, vgg_path):\n","    \"\"\"\n","    Load Pretrained VGG Model into TensorFlow.\n","    :param sess: TensorFlow Session\n","    :param vgg_path: Path to vgg folder, containing \"variables/\" and \"saved_model.pb\"\n","    :return: Tuple of Tensors from VGG model (image_input, keep_prob, layer3_out, layer4_out, layer7_out)\n","    \"\"\"\n","    # TODO: Implement function\n","    #   Use tf.saved_model.loader.load to load the model and weights\n","    \n","    vgg_tag = 'vgg16'\n","     \n","    vgg_input_tensor_name = 'image_input:0'\n","    vgg_keep_prob_tensor_name = 'keep_prob:0'\n","    vgg_layer3_out_tensor_name = 'layer3_out:0'\n","    vgg_layer4_out_tensor_name = 'layer4_out:0'\n","    vgg_layer7_out_tensor_name = 'layer7_out:0'\n","    \n","    tf.saved_model.loader.load(sess, [vgg_tag], vgg_path)\n","    graph = tf.get_default_graph()\n","    w1 = graph.get_tensor_by_name(vgg_input_tensor_name)\n","    keep = graph.get_tensor_by_name(vgg_keep_prob_tensor_name)\n","    layer3 = graph.get_tensor_by_name(vgg_layer3_out_tensor_name)\n","    layer4 = graph.get_tensor_by_name(vgg_layer4_out_tensor_name)\n","    layer7 = graph.get_tensor_by_name(vgg_layer7_out_tensor_name)\n","    \n","    \n","    return w1, keep, layer3, layer4, layer7\n","tests.test_load_vgg(load_vgg, tf)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Tests Passed\n"],"name":"stdout"}]},{"metadata":{"id":"E3hisI7fAFv9","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"e75efd0e-dfcf-4d67-fdfb-badbba1e3ed4","executionInfo":{"status":"ok","timestamp":1532199746765,"user_tz":420,"elapsed":542,"user":{"displayName":"vamshi korivi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"112593885874769367656"}}},"cell_type":"code","source":["def layers(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes):\n","    \"\"\"\n","    Create the layers for a fully convolutional network.  Build skip-layers using the vgg layers.\n","    :param vgg_layer3_out: TF Tensor for VGG Layer 3 output\n","    :param vgg_layer4_out: TF Tensor for VGG Layer 4 output\n","    :param vgg_layer7_out: TF Tensor for VGG Layer 7 output\n","    :param num_classes: Number of classes to classify\n","    :return: The Tensor for the last layer of output\n","    \"\"\"\n","    # TODO: Implement function\n","    # Doing Skip Layers\n","    vgg_layer7_conv_1x1 = tf.layers.conv2d(vgg_layer7_out, num_classes, 1, padding='same', \n","                                kernel_regularizer = tf.contrib.layers.l2_regularizer(1e-3))\n","    vgg_layer4_conv_1x1 = tf.layers.conv2d(vgg_layer4_out, num_classes, 1, padding='same', \n","                                kernel_regularizer = tf.contrib.layers.l2_regularizer(1e-3))\n","    vgg_layer3_conv_1x1 = tf.layers.conv2d(vgg_layer3_out, num_classes, 1, padding='same', \n","                                kernel_regularizer = tf.contrib.layers.l2_regularizer(1e-3))\n","    \n","    #deconv layer,upsampling and skip\n","    #kernel_size=4, strides=2\n","    layer7_output = tf.layers.conv2d_transpose(vgg_layer7_conv_1x1, num_classes, 4, 2, padding='same', \n","                                       kernel_regularizer = tf.contrib.layers.l2_regularizer(1e-3))\n","    \n","    skip_layer_4 = tf.add(layer7_output, vgg_layer4_conv_1x1)\n","    \n","    layer4_output = tf.layers.conv2d_transpose(skip_layer_4, num_classes, 4, 2, padding='same', \n","                                       kernel_regularizer = tf.contrib.layers.l2_regularizer(1e-3))\n","    \n","    skip_layer_3 = tf.add(layer4_output, vgg_layer3_conv_1x1)\n","    \n","    output_layer = tf.layers.conv2d_transpose(skip_layer_3, num_classes, 16, 8, padding='same',  kernel_initializer= tf.random_normal_initializer(stddev=0.01),\n","                                             kernel_regularizer = tf.contrib.layers.l2_regularizer(1e-3));\n","    \n","    \n","    return output_layer\n","tests.test_layers(layers)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Tests Passed\n"],"name":"stdout"}]},{"metadata":{"id":"zYWRgtJYOO2z","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"9c9ff03a-e8a7-461b-d5d1-bc41411dea55","executionInfo":{"status":"ok","timestamp":1532201039541,"user_tz":420,"elapsed":378,"user":{"displayName":"vamshi korivi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"112593885874769367656"}}},"cell_type":"code","source":["def optimize(nn_last_layer, correct_label, learning_rate, num_classes):\n","    \"\"\"\n","    Build the TensorFLow loss and optimizer operations.\n","    :param nn_last_layer: TF Tensor of the last layer in the neural network\n","    :param correct_label: TF Placeholder for the correct label image\n","    :param learning_rate: TF Placeholder for the learning rate\n","    :param num_classes: Number of classes to classify\n","    :return: Tuple of (logits, train_op, cross_entropy_loss)\n","    \"\"\"\n","    # TODO: Implement function\n","    logits = tf.reshape(nn_last_layer, (-1, num_classes))\n","    labels = tf.reshape(correct_label, (-1, num_classes))\n","    \n","    cross_entropy_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n","\n","    trainOptimizer = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy_loss)\n","    \n","    return logits, trainOptimizer, cross_entropy_loss\n","tests.test_optimize(optimize)\n"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Tests Passed\n"],"name":"stdout"}]},{"metadata":{"id":"ZMzhlEJGOS4R","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def train_nn(sess, epochs, batch_size, get_batches_fn, train_op, cross_entropy_loss, input_image,\n","             correct_label, keep_prob, learning_rate):\n","    \"\"\"\n","    Train neural network and print out the loss during training.\n","    :param sess: TF Session\n","    :param epochs: Number of epochs\n","    :param batch_size: Batch size\n","    :param get_batches_fn: Function to get batches of training data.  Call using get_batches_fn(batch_size)\n","    :param train_op: TF Operation to train the neural network\n","    :param cross_entropy_loss: TF Tensor for the amount of loss\n","    :param input_image: TF Placeholder for input images\n","    :param correct_label: TF Placeholder for label images\n","    :param keep_prob: TF Placeholder for dropout keep probability\n","    :param learning_rate: TF Placeholder for learning rate\n","    \"\"\"\n","    # TODO: Implement function\n","    for epoch in range(epochs):\n","      for image, lable in get_batches_fn(batch_size):\n","        _, loss = sess.run([train_op, cross_entropy_loss],\n","            feed_dict={input_image: image, correct_label: lable, keep_prob:0.75, learning_rate:0.0001})\n","        print(\"Loss: = {:.2f}\".format(loss))\n","        \n","tests.test_train_nn(train_nn)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vpHK1GuGckZC","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!wget  https://s3.eu-central-1.amazonaws.com/avg-kitti/data_road.zip"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HVAA_wkrdIP_","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!unzip data_road.zip"],"execution_count":0,"outputs":[]},{"metadata":{"id":"efYfIkaQOXb4","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":122},"outputId":"8fecbd58-3e17-452e-f362-0e3e9ce30b2a","executionInfo":{"status":"ok","timestamp":1532216762300,"user_tz":420,"elapsed":2415241,"user":{"displayName":"vamshi korivi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"112593885874769367656"}}},"cell_type":"code","source":["def run():\n","    num_classes = 2\n","    image_shape = (160, 576)\n","    data_dir = ''\n","    runs_dir = './runs'\n","    tests.test_for_kitti_dataset(data_dir)\n","\n","    # Download pretrained vgg model\n","    helper.maybe_download_pretrained_vgg(data_dir)\n","\n","    # OPTIONAL: Train and Inference on the cityscapes dataset instead of the Kitti dataset.\n","    # You'll need a GPU with at least 10 teraFLOPS to train on.\n","    #  https://www.cityscapes-dataset.com/\n","\n","    with tf.Session() as sess:\n","        # Path to vgg model\n","        vgg_path = os.path.join(data_dir, 'vgg')\n","        # Create function to get batches\n","        get_batches_fn = helper.gen_batch_function(os.path.join(data_dir, 'data_road/training'), image_shape)\n","\n","        # OPTIONAL: Augment Images for better results\n","        #  https://datascience.stackexchange.com/questions/5224/how-to-prepare-augment-images-for-neural-network\n","\n","        # TODO: Build NN using load_vgg, layers, and optimize function\n","        input_image, keep_prob, layer3_out, layer4_out, layer7_out = load_vgg(sess, vgg_path)\n","        \n","        layer_output = layers(layer3_out, layer4_out, layer7_out, num_classes)\n","                              \n","        correct_label = tf.placeholder(tf.int32, shape = [None, None, None, num_classes], name='correct_label')\n","        learning_rate = tf.placeholder(tf.float32)\n","                              \n","        logits, train_op, cross_entropy_loss = optimize(layer_output, correct_label, learning_rate, num_classes)\n","        sess.run(tf.global_variables_initializer())\n","        \n","        epochs = 30\n","        batch_size = 5\n","\n","        # TODO: Train NN using the train_nn function\n","        train_nn(sess, epochs, batch_size, get_batches_fn, train_op, cross_entropy_loss, input_image, correct_label, keep_prob, learning_rate)\n","\n","        # TODO: Save inference data using helper.save_inference_samples\n","        helper.save_inference_samples(runs_dir, data_dir, sess, image_shape, logits, keep_prob, input_image)\n","\n","        # OPTIONAL: Apply the trained model to a video\n","\n","\n","if __name__ == '__main__':\n","    run()\n"],"execution_count":33,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from vgg/variables/variables\n","/usr/local/lib/python3.6/dist-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if issubdtype(ts, int):\n","/usr/local/lib/python3.6/dist-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n","  elif issubdtype(type(size), float):\n"],"name":"stderr"}]},{"metadata":{"id":"e8QSWP7wImBS","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!zip -r sdcsruns.zip runs/"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lkU-MfjpStHg","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["files.download('sdcsruns.zip')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"D-3VQ8rrdzvG","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"69430264-79c5-4178-9fd3-6e61fb4025c9","executionInfo":{"status":"ok","timestamp":1532203847102,"user_tz":420,"elapsed":315,"user":{"displayName":"vamshi korivi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"112593885874769367656"}}},"cell_type":"code","source":["run()"],"execution_count":23,"outputs":[{"output_type":"stream","text":["ERROR:root:File `'().py'` not found.\n"],"name":"stderr"}]}]}